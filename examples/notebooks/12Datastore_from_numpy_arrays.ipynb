{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Creating a DataStore from numpy arrays\n",
    "The goal of this notebook is to demonstrate how to create a `DataStore` from scratch. This can be useful if your device is not supported or if you would like to integrate the `dtscalibration` library in your current routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T08:38:15.873345Z",
     "iopub.status.busy": "2021-05-12T08:38:15.870079Z",
     "iopub.status.idle": "2021-05-12T08:38:17.216020Z",
     "shell.execute_reply": "2021-05-12T08:38:17.216456Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "from dtscalibration import DataStore, read_silixa_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a `DataStore` object, a few things are needed:\n",
    "\n",
    "- timestamps\n",
    "\n",
    "- Stokes signal\n",
    "\n",
    "- anti-Stokes signal\n",
    "\n",
    "- x (length along fiber)\n",
    "\n",
    "Let's grab the data from an existing silixa dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T08:38:17.221199Z",
     "iopub.status.busy": "2021-05-12T08:38:17.220385Z",
     "iopub.status.idle": "2021-05-12T08:38:17.328874Z",
     "shell.execute_reply": "2021-05-12T08:38:17.329354Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join('..', '..', 'tests', 'data', 'single_ended')\n",
    "\n",
    "ds_silixa = read_silixa_files(directory=filepath,\n",
    "                              silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get all the numpy arrays from this `DataStore` to create a new one from 'scratch'.\n",
    "\n",
    "Let's start with the most basic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T08:38:17.333805Z",
     "iopub.status.busy": "2021-05-12T08:38:17.333230Z",
     "iopub.status.idle": "2021-05-12T08:38:17.335444Z",
     "shell.execute_reply": "2021-05-12T08:38:17.334992Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ds_silixa.x.values\n",
    "time = ds_silixa.time.values\n",
    "ST = ds_silixa.st.values\n",
    "AST = ds_silixa.ast.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data has to be inserted into an xarray `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T08:38:17.342888Z",
     "iopub.status.busy": "2021-05-12T08:38:17.342105Z",
     "iopub.status.idle": "2021-05-12T08:38:17.345263Z",
     "shell.execute_reply": "2021-05-12T08:38:17.346125Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = xr.Dataset()\n",
    "ds['x'] = ('x', x)\n",
    "ds['time'] = ('time', time)\n",
    "ds['st'] = (['x', 'time'], ST)\n",
    "ds['ast'] = (['x', 'time'], AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T08:38:17.356809Z",
     "iopub.status.busy": "2021-05-12T08:38:17.350889Z",
     "iopub.status.idle": "2021-05-12T08:38:17.360398Z",
     "shell.execute_reply": "2021-05-12T08:38:17.361087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtscalibration.DataStore>\n",
      "Sections:                  ()\n",
      "Dimensions:    (time: 3, trans_att: 0, x: 1461)\n",
      "Coordinates:\n",
      "  * x          (x) float64 -80.74 -80.62 -80.49 -80.36 ... 104.6 104.7 104.8\n",
      "  * time       (time) datetime64[ns] 2018-05-04T12:22:17.710000 ... 2018-05-0...\n",
      "  * trans_att  (trans_att) float64 \n",
      "Data variables:\n",
      "    st         (x, time) float64 -0.8058 0.4287 -0.513 ... 27.99 27.83 28.81\n",
      "    ast        (x, time) float64 -0.2459 -0.5932 0.1111 ... 36.2 35.7 35.16\n",
      "Attributes:\n",
      "    _sections:  null\\n...\\n\n"
     ]
    }
   ],
   "source": [
    "ds = DataStore(ds)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For calibration, a few more paramaters are needed:\n",
    "\n",
    "- acquisition time (for calculating residuals for WLS calibration)\n",
    "\n",
    "- reference temperatures\n",
    "\n",
    "- a double ended flag\n",
    "\n",
    "We'll put these into the custom `DataStore`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T08:38:17.370951Z",
     "iopub.status.busy": "2021-05-12T08:38:17.368847Z",
     "iopub.status.idle": "2021-05-12T08:38:17.374282Z",
     "shell.execute_reply": "2021-05-12T08:38:17.374850Z"
    }
   },
   "outputs": [],
   "source": [
    "ds['acquisitiontimeFW'] = ds_silixa['acquisitiontimeFW'].values\n",
    "ds['temp1'] = ds_silixa['probe1Temperature']\n",
    "ds['temp2'] = ds_silixa['probe2Temperature']\n",
    "\n",
    "ds.attrs['isDoubleEnded'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calibrate the data as usual (ordinary least squares in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T08:38:17.384140Z",
     "iopub.status.busy": "2021-05-12T08:38:17.383440Z",
     "iopub.status.idle": "2021-05-12T08:38:17.476090Z",
     "shell.execute_reply": "2021-05-12T08:38:17.476502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/git/python-dts-calibration/.tox/docs/lib/python3.7/site-packages/dask/array/core.py:1495: FutureWarning: The `numpy.ndim` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f47b03f8850>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.sel(x=slice(-30, 101))\n",
    "sections = {\n",
    "            'temp1':    [slice(20, 25.5)],  # warm bath\n",
    "            'temp2':    [slice(5.5, 15.5)],  # cold bath\n",
    "            }\n",
    "ds.sections = sections\n",
    "\n",
    "ds.calibration_single_ended(method='ols')\n",
    "\n",
    "ds.isel(time=0).tmpf.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
